#!/bin/bash

# Local Image Generation Installation Script
# This script installs all dependencies needed for local SDXL image generation

set -e  # Exit on any error

echo "ğŸš€ Installing Local Image Generation Dependencies..."
echo "=================================================="
echo ""

# Check if we're in the right directory
if [ ! -f "requirements.txt" ]; then
    echo "âŒ Error: Please run this script from the 'be' directory"
    exit 1
fi

# Check Python version
python_version=$(python3 --version 2>&1 | grep -oE '[0-9]+\.[0-9]+' | head -1)
required_version="3.8"

if [ "$(printf '%s\n' "$required_version" "$python_version" | sort -V | head -n1)" != "$required_version" ]; then
    echo "âŒ Error: Python 3.8+ required, found Python $python_version"
    exit 1
fi

echo "âœ… Python version: $python_version"
echo ""

# Detect system and GPU
echo "ğŸ” Detecting system configuration..."

if command -v nvidia-smi &> /dev/null; then
    echo "âœ… NVIDIA GPU detected"
    gpu_type="nvidia"
    
    # Get CUDA version
    cuda_version=$(nvidia-smi --query-gpu=compute_cap --format=csv,noheader,nounits | head -1)
    echo "   CUDA Compute Capability: $cuda_version"
    
    # Get VRAM
    vram=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
    echo "   VRAM: $vram MB"
    
elif [[ "$OSTYPE" == "darwin"* ]]; then
    if [[ $(uname -m) == "arm64" ]]; then
        echo "âœ… Apple Silicon (M1/M2) detected"
        gpu_type="apple"
    else
        echo "âœ… macOS Intel detected"
        gpu_type="macos"
    fi
else
    echo "â„¹ï¸  No GPU detected, will use CPU (slower but functional)"
    gpu_type="cpu"
fi

echo ""

# Install PyTorch based on system
echo "ğŸ“¦ Installing PyTorch..."

case $gpu_type in
    "nvidia")
        echo "   Installing PyTorch with CUDA support..."
        
        # Try CUDA 12.1 first, fallback to 11.8
        if pip install --upgrade torch torchvision --index-url https://download.pytorch.org/whl/cu121 --quiet; then
            echo "   âœ… PyTorch with CUDA 12.1 installed"
        elif pip install --upgrade torch torchvision --index-url https://download.pytorch.org/whl/cu118 --quiet; then
            echo "   âœ… PyTorch with CUDA 11.8 installed"
        else
            echo "   âŒ Failed to install PyTorch with CUDA"
            exit 1
        fi
        ;;
    "apple")
        echo "   Installing PyTorch for Apple Silicon..."
        pip install --upgrade torch torchvision --quiet
        echo "   âœ… PyTorch for Apple Silicon installed"
        ;;
    *)
        echo "   Installing PyTorch for CPU..."
        pip install --upgrade torch torchvision --quiet
        echo "   âœ… PyTorch for CPU installed"
        ;;
esac

echo ""

# Install SDXL dependencies
echo "ğŸ“¦ Installing SDXL dependencies..."

echo "   Installing diffusers, transformers, accelerate..."
pip install diffusers transformers accelerate --quiet

echo "   Installing safetensors, compel, Pillow..."
pip install safetensors compel Pillow --quiet

# Install xformers for NVIDIA GPUs (optional but recommended)
if [ "$gpu_type" = "nvidia" ]; then
    echo "   Installing xformers for memory optimization..."
    if pip install xformers --quiet; then
        echo "   âœ… xformers installed"
    else
        echo "   âš ï¸  xformers installation failed (optional, continuing...)"
    fi
fi

echo ""

# Install all requirements
echo "ğŸ“¦ Installing all project dependencies..."
pip install -r requirements.txt --quiet
echo "âœ… All dependencies installed"
echo ""

# Check if Hugging Face CLI is available
if command -v huggingface-cli &> /dev/null; then
    echo "âœ… Hugging Face CLI available"
else
    echo "ğŸ“¦ Installing Hugging Face CLI..."
    pip install huggingface_hub --quiet
    echo "âœ… Hugging Face CLI installed"
fi

echo ""

# Create .env file if it doesn't exist
if [ ! -f ".env.development" ]; then
    echo "ğŸ“ Creating .env.development file..."
    cat > .env.development << EOF
# Local Image Generation Configuration
# Add your OpenAI API key for content generation
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Override default settings
APP_ENV=development
OPENAI_MODEL=gpt-4o-mini
EOF
    echo "âœ… .env.development file created"
    echo "   âš ï¸  Please add your OpenAI API key to .env.development"
else
    echo "âœ… .env.development file already exists"
fi

echo ""

# Final instructions
echo "ğŸ‰ Installation Complete!"
echo "========================"
echo ""
echo "Next steps:"
echo "1. Add your OpenAI API key to .env.development"
echo "2. Login to Hugging Face (if needed):"
echo "   huggingface-cli login"
echo "3. Test the installation:"
echo "   python test_local_image.py"
echo "4. Start the server:"
echo "   uvicorn app.main:app --reload"
echo ""
echo "ğŸ“š For detailed documentation, see README_LOCAL_IMAGE.md"
echo ""

# Test if we can import the modules
echo "ğŸ§ª Testing imports..."
if python3 -c "
import torch
import diffusers
import transformers
import accelerate
import safetensors
import compel
from PIL import Image
print('âœ… All modules imported successfully')
" 2>/dev/null; then
    echo "âœ… Import test passed"
else
    echo "âŒ Import test failed - check installation"
    exit 1
fi

echo ""
echo "ğŸš€ Ready to generate images locally with Stable Diffusion XL!"
