# Local Image Generation with Stable Diffusion XL

This backend now supports local image generation using Stable Diffusion XL via Hugging Face Diffusers, completely replacing the OpenAI image generation while maintaining the same API interface.

## üöÄ Features

- **Local Generation**: No external API calls, no rate limits, no costs
- **SDXL Quality**: Uses Stable Diffusion XL Base + optional Refiner for high-quality images
- **SDXL Turbo**: Fast generation mode for quick iterations
- **Smart Prompting**: Automatic prompt building from travel content data
- **Device Optimization**: Automatic device detection (CUDA ‚Üí MPS ‚Üí CPU)
- **Memory Management**: Automatic size adjustment based on available VRAM
- **Data URL Output**: Images returned as base64 data URLs (no disk writes)

## üì¶ Installation

### 1. System Requirements

- **Python**: 3.8+
- **Memory**: Minimum 8GB RAM, 16GB+ recommended
- **GPU**: NVIDIA GPU with 8GB+ VRAM recommended (CUDA 11.8+)
- **Alternative**: Apple Silicon (M1/M2) with MPS support
- **Fallback**: CPU-only mode (slower but functional)

### 2. Install Dependencies

```bash
# Navigate to backend directory
cd be

# Install PyTorch (choose appropriate version for your system)
# For NVIDIA CUDA 11.8:
pip install --upgrade torch torchvision --index-url https://download.pytorch.org/whl/cu118

# For NVIDIA CUDA 12.1:
pip install --upgrade torch torchvision --index-url https://download.pytorch.org/whl/cu121

# For CPU-only:
pip install torch torchvision

# For Apple Silicon (M1/M2):
pip install torch torchvision

# Install SDXL dependencies
pip install diffusers transformers accelerate safetensors compel Pillow

# Optional: Install xformers for memory optimization (CUDA only)
pip install xformers
```

### 3. Install All Dependencies

```bash
# Install everything from requirements.txt
pip install -r requirements.txt
```

### 4. Model Downloads

The system will automatically download required models on first run:

- **SDXL Base**: `stabilityai/stable-diffusion-xl-base-1.0` (~6.9GB)
- **SDXL Refiner**: `stabilityai/stable-diffusion-xl-refiner-1.0` (~6.9GB) 
- **SDXL Turbo**: `stabilityai/sdxl-turbo` (~6.9GB)

**Note**: Some models require Hugging Face EULA acceptance:
```bash
huggingface-cli login
```

## üîß Configuration

### Environment Variables

Create a `.env.development` file in the `be/` directory:

```bash
# Required for content generation (OpenAI)
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Override default settings
APP_ENV=development
OPENAI_MODEL=gpt-4o-mini
```

### Device Detection

The system automatically detects the best available device:

1. **CUDA** (NVIDIA GPU) - Best performance, supports all features
2. **MPS** (Apple Silicon) - Good performance, limited features
3. **CPU** - Slowest but always available

## üì° API Endpoints

### 1. New Local Image Generation

**POST** `/api/v1/generate-image-local`

```json
{
  "title": "Late-morning bites at Borough Market",
  "content": "Arrive by late morning for coffee and pastries; weave past fruit crates and cheese counters under the iron arches.",
  "destination": "London",
  "tags": ["market", "street food"],
  "neighborhoods": ["Southwark"],
  "recommended_spots": ["Borough Market"],
  "best_times": "late morning",
  "width": 1792,
  "height": 1024,
  "mode": "quality"
}
```

**Response:**
```json
{
  "image_prompt": "Borough Market in London; morning; street-level, 24‚Äì35mm wide-angle; people mid-ground, leading lines; soft daylight; natural balanced colors; documentary travel photo captured on a full-frame camera, 35mm lens, f/5.6, 1/250s, ISO 200; realistic depth of field, subtle sensor noise, natural color grading, minimal post-processing; photorealistic, sharp focus, high detail. Must include: market stalls, vendor awnings, fruit crates, cheese counter. AVOID: no text overlays, no watermarks, no logos, no billboards, no heavy HDR, no anime, no illustration, no digital painting, no concept art, no CGI, no 3D render, no matte painting, no stylized look, no fisheye, avoid motion blur.",
  "alt_text": "Borough Market in London at morning, showing market stalls, vendor awnings, fruit crates",
  "image_url": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...",
  "error": null
}
```

### 2. Legacy Endpoint (Redirects to Local)

**POST** `/api/v1/generate-image`

The legacy OpenAI endpoint now automatically uses local SDXL generation, maintaining backward compatibility.

## üéØ Generation Modes

### Quality Mode (Default)
- **Pipeline**: SDXL Base + optional Refiner
- **Steps**: 28-36 inference steps
- **Guidance**: 5.0-6.0 CFG scale
- **Quality**: Highest quality, slower generation
- **Use Case**: Production images, final outputs

### Turbo Mode
- **Pipeline**: SDXL Turbo
- **Steps**: 4-6 inference steps  
- **Guidance**: 0.0 CFG scale (ignored by Turbo)
- **Quality**: Good quality, very fast generation
- **Use Case**: Quick iterations, prototyping

## üé® Prompt Engineering

The system automatically builds sophisticated prompts from your input data:

### Place Selection Priority
1. **Title** ‚Üí extract market/street/plaza/square/park/museum/cathedral/bridge
2. **Recommended Spots** ‚Üí first item in list
3. **Neighborhoods** ‚Üí first item in list  
4. **Destination** ‚Üí fallback

### Time/Season Inference
- `"late morning"` ‚Üí `morning`
- `"sunset"` ‚Üí `sunset`
- `"night"` ‚Üí `night`
- `"winter"` ‚Üí `winter`

### Composition & Lighting
- **Street scenes**: Wide-angle, people mid-ground, leading lines
- **Waterfront**: Elevated vantage, foreground anchor, sweeping background
- **General**: Eye-level, center-weighted subject

### Style Anchor
Appends professional photography specifications for consistent, realistic results.

## üß™ Testing

### Quick Test

```bash
cd be
python test_local_image.py
```

### API Test

```bash
# Start the server
uvicorn app.main:app --reload

# Test with curl
curl -X POST "http://localhost:8000/api/v1/generate-image-local" \
  -H "Content-Type: application/json" \
  -d '{
    "destination": "London",
    "recommended_spots": ["Borough Market"],
    "best_times": "morning"
  }'
```

## üö® Troubleshooting

### Common Issues

#### 1. CUDA Out of Memory
```bash
# Reduce image size in request
"width": 1024, "height": 1024

# Or use turbo mode
"mode": "turbo"
```

#### 2. Model Download Failures
```bash
# Login to Hugging Face
huggingface-cli login

# Check internet connection and try again
```

#### 3. Slow Generation on CPU
```bash
# This is expected - CPU generation is much slower
# Consider using a GPU or cloud service for production
```

#### 4. MPS (Apple Silicon) Issues
```bash
# MPS support is limited in some PyTorch versions
# Try updating to latest PyTorch version
pip install --upgrade torch torchvision
```

### Performance Optimization

#### CUDA Optimizations
- **VAE Slicing**: Automatically enabled for memory efficiency
- **VAE Tiling**: Enabled for large images
- **Attention Slicing**: Enabled for memory efficiency

#### Memory Management
- **Automatic Size Adjustment**: Based on available VRAM
- **Pipeline Sharing**: Models loaded once and reused
- **Garbage Collection**: Automatic cleanup after generation

## üìä Performance Benchmarks

| Device | Mode | Size | Time | Quality |
|--------|------|------|------|---------|
| RTX 4090 (24GB) | Quality | 1792x1024 | ~15s | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| RTX 3080 (10GB) | Quality | 1536x896 | ~25s | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| RTX 3060 (8GB) | Turbo | 1024x1024 | ~8s | ‚≠ê‚≠ê‚≠ê‚≠ê |
| M1 Pro | Quality | 1024x1024 | ~45s | ‚≠ê‚≠ê‚≠ê‚≠ê |
| CPU (i7) | Turbo | 1024x1024 | ~5min | ‚≠ê‚≠ê‚≠ê |

## üîí Security & Privacy

- **No External Calls**: All processing happens locally
- **No Data Storage**: Images returned as data URLs, no disk writes
- **No Logging**: Image data not logged or stored
- **Model Safety**: Uses Hugging Face's safety-filtered models

## üöÄ Production Deployment

### Docker
```dockerfile
# Use GPU-enabled base image for CUDA support
FROM nvidia/cuda:11.8-devel-ubuntu20.04

# Install Python and dependencies
RUN apt-get update && apt-get install -y python3 python3-pip
COPY requirements.txt .
RUN pip3 install -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Run with GPU support
CMD ["python3", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Environment Variables
```bash
# Production settings
APP_ENV=production
CUDA_VISIBLE_DEVICES=0  # Use specific GPU
TORCH_CUDA_ARCH_LIST="7.5;8.0;8.6"  # Optimize for specific GPU architectures
```

## üìö Additional Resources

- [Stable Diffusion XL Documentation](https://huggingface.co/docs/diffusers/using-diffusers/sdxl)
- [Diffusers Library](https://github.com/huggingface/diffusers)
- [PyTorch Installation Guide](https://pytorch.org/get-started/locally/)
- [Hugging Face Models](https://huggingface.co/stabilityai)

## ü§ù Support

For issues or questions:
1. Check the troubleshooting section above
2. Review the logs for error messages
3. Test with the provided test script
4. Check system requirements and dependencies

---

**Note**: This system replaces OpenAI image generation completely. The content generation still uses OpenAI for text generation, but all images are now generated locally using Stable Diffusion XL.
